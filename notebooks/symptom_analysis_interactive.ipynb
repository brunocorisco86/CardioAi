{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü©∫ An√°lise Interativa de Sintomas Cardiovasculares\n",
    "\n",
    "Este notebook utiliza Processamento de Linguagem Natural (**spaCy**) e uma base de conhecimento para analisar frases de pacientes e sugerir um diagn√≥stico principal, sintoma e grau de risco.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instala√ß√£o e Configura√ß√£o Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/brunoconter/.local/lib/python3.13/site-packages (2.3.2)\n",
      "Requirement already satisfied: spacy in /home/brunoconter/.local/lib/python3.13/site-packages (3.8.7)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/lib64/python3.13/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/lib/python3.13/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/brunoconter/.local/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/brunoconter/.local/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/brunoconter/.local/lib/python3.13/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/brunoconter/.local/lib/python3.13/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/brunoconter/.local/lib/python3.13/site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/brunoconter/.local/lib/python3.13/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/brunoconter/.local/lib/python3.13/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /home/brunoconter/.local/lib/python3.13/site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/brunoconter/.local/lib/python3.13/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/brunoconter/.local/lib/python3.13/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/brunoconter/.local/lib/python3.13/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /home/brunoconter/.local/lib/python3.13/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /home/brunoconter/.local/lib/python3.13/site-packages (from spacy) (0.19.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/brunoconter/.local/lib/python3.13/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3.13/site-packages (from spacy) (2.32.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/brunoconter/.local/lib/python3.13/site-packages (from spacy) (2.11.10)\n",
      "Requirement already satisfied: jinja2 in /home/brunoconter/.local/lib/python3.13/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3.13/site-packages (from spacy) (74.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3.13/site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/brunoconter/.local/lib/python3.13/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /home/brunoconter/.local/lib/python3.13/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/brunoconter/.local/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/brunoconter/.local/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/brunoconter/.local/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /home/brunoconter/.local/lib/python3.13/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/brunoconter/.local/lib/python3.13/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/lib/python3.13/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/brunoconter/.local/lib/python3.13/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/brunoconter/.local/lib/python3.13/site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.1.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /home/brunoconter/.local/lib/python3.13/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.22.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /home/brunoconter/.local/lib/python3.13/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib64/python3.13/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /home/brunoconter/.local/lib/python3.13/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/brunoconter/.local/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/brunoconter/.local/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: wrapt in /home/brunoconter/.local/lib/python3.13/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/brunoconter/.local/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pt-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "# Instala as bibliotecas necess√°rias (Pandas e spaCy)\n",
    "!pip install pandas spacy\n",
    "\n",
    "# Baixa o modelo de linguagem em portugu√™s. Isso √© crucial para a similaridade.\n",
    "!python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregamento das Bibliotecas e Modelo NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelo spaCy em Portugu√™s carregado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "nlp = None\n",
    "# Tenta carregar o modelo de linguagem\n",
    "try:\n",
    "    nlp = spacy.load(\"pt_core_news_sm\")\n",
    "    print(\"‚úÖ Modelo spaCy em Portugu√™s carregado com sucesso!\")\n",
    "except OSError:\n",
    "    print(\"‚ùå ERRO: Modelo 'pt_core_news_sm' n√£o encontrado.\")\n",
    "    print(\"Certifique-se de executar o comando de download na c√©lula anterior.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Carregamento da Base de Conhecimento\n",
    "\n",
    "**ATEN√á√ÉO**: Certifique-se de que o arquivo CSV (`tabela_sintoma_diagnostico_risco.csv`) est√° no mesmo diret√≥rio deste notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Base de conhecimento carregada com sucesso!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Express√£o em 1¬™ Pessoa</th>\n",
       "      <th>Sintoma Cardiovascular</th>\n",
       "      <th>Grau de Risco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sinto falta de ar ao deitar ou preciso usar ma...</td>\n",
       "      <td>Dispneia Parox√≠stica Noturna (DPN) / Ortopneia</td>\n",
       "      <td>Alto Risco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Percebi incha√ßo nas pernas ou tornozelos.</td>\n",
       "      <td>Edema de Membros Inferiores</td>\n",
       "      <td>M√©dio Risco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Notei palpita√ß√µes ou batimentos card√≠acos irre...</td>\n",
       "      <td>Palpita√ß√µes (Arritmia)</td>\n",
       "      <td>M√©dio Risco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sinto dor ou press√£o no peito ao fazer esfor√ßo...</td>\n",
       "      <td>Angina de Esfor√ßo</td>\n",
       "      <td>Alto Risco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J√° acordei √† noite com falta de ar s√∫bita.</td>\n",
       "      <td>Dispneia Parox√≠stica Noturna (DPN)</td>\n",
       "      <td>Alto Risco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Observei colora√ß√£o azulada nos l√°bios ou extre...</td>\n",
       "      <td>Cianose</td>\n",
       "      <td>Alto Risco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tenho sentido tontura ou desmaios, especialmen...</td>\n",
       "      <td>S√≠ncope / Hipotens√£o Postural</td>\n",
       "      <td>Alto Risco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Percebo pulsa√ß√£o forte ou vis√≠vel no pesco√ßo.</td>\n",
       "      <td>Estase Jugular</td>\n",
       "      <td>Alto Risco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sinto dor ou desconforto ao inspirar profundam...</td>\n",
       "      <td>Dor Pleur√≠tica</td>\n",
       "      <td>M√©dio Risco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Notei batimentos card√≠acos muito acelerados ou...</td>\n",
       "      <td>Taquicardia / Bradicardia</td>\n",
       "      <td>M√©dio Risco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Express√£o em 1¬™ Pessoa  \\\n",
       "0  Sinto falta de ar ao deitar ou preciso usar ma...   \n",
       "1          Percebi incha√ßo nas pernas ou tornozelos.   \n",
       "2  Notei palpita√ß√µes ou batimentos card√≠acos irre...   \n",
       "3  Sinto dor ou press√£o no peito ao fazer esfor√ßo...   \n",
       "4         J√° acordei √† noite com falta de ar s√∫bita.   \n",
       "5  Observei colora√ß√£o azulada nos l√°bios ou extre...   \n",
       "6  Tenho sentido tontura ou desmaios, especialmen...   \n",
       "7      Percebo pulsa√ß√£o forte ou vis√≠vel no pesco√ßo.   \n",
       "8  Sinto dor ou desconforto ao inspirar profundam...   \n",
       "9  Notei batimentos card√≠acos muito acelerados ou...   \n",
       "\n",
       "                           Sintoma Cardiovascular Grau de Risco  \n",
       "0  Dispneia Parox√≠stica Noturna (DPN) / Ortopneia    Alto Risco  \n",
       "1                     Edema de Membros Inferiores   M√©dio Risco  \n",
       "2                          Palpita√ß√µes (Arritmia)   M√©dio Risco  \n",
       "3                               Angina de Esfor√ßo    Alto Risco  \n",
       "4              Dispneia Parox√≠stica Noturna (DPN)    Alto Risco  \n",
       "5                                         Cianose    Alto Risco  \n",
       "6                   S√≠ncope / Hipotens√£o Postural    Alto Risco  \n",
       "7                                  Estase Jugular    Alto Risco  \n",
       "8                                  Dor Pleur√≠tica   M√©dio Risco  \n",
       "9                       Taquicardia / Bradicardia   M√©dio Risco  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KNOWLEDGE_BASE_FILE = \"../assets/tabela_sintoma_diagnostico_risco.csv\"\n",
    "\n",
    "def load_knowledge_base(file_path, nlp_model):\n",
    "    \"\"\"Carrega a base de conhecimento e pr√©-processa as express√µes com spaCy.\"\"\"\n",
    "    if nlp_model is None:\n",
    "        return None\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        # Cria o objeto spaCy (doc) para cada express√£o de primeira pessoa\n",
    "        df['doc'] = list(nlp_model.pipe(df['Express√£o em 1¬™ Pessoa']))\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Erro: Arquivo da base de conhecimento n√£o encontrado em '{file_path}'\")\n",
    "        return None\n",
    "    except KeyError:\n",
    "        print(\"‚ùå Erro: Colunas esperadas ('Express√£o em 1¬™ Pessoa') n√£o encontradas no CSV.\")\n",
    "        return None\n",
    "\n",
    "knowledge_base_df = load_knowledge_base(KNOWLEDGE_BASE_FILE, nlp)\n",
    "\n",
    "if knowledge_base_df is not None:\n",
    "    print(\"‚úÖ Base de conhecimento carregada com sucesso!\")\n",
    "    display(knowledge_base_df[['Express√£o em 1¬™ Pessoa', 'Sintoma Cardiovascular', 'Grau de Risco']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fun√ß√£o de An√°lise e Correspond√™ncia (NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisar_sintoma_interativo(frase_usuario, base_conhecimento, nlp_model, limiar_similaridade=0.7):\n",
    "    \"\"\"Analisa a frase do usu√°rio usando similaridade de vetores spaCy.\"\"\"\n",
    "    if base_conhecimento is None or nlp_model is None:\n",
    "        print(\"A base de conhecimento ou o modelo NLP n√£o foi carregado.\")\n",
    "        return\n",
    "\n",
    "    # Processa a frase do usu√°rio\n",
    "    doc_usuario = nlp_model(frase_usuario.strip().lower())\n",
    "\n",
    "    # Calcula a similaridade entre a frase do usu√°rio e todas as express√µes da base\n",
    "    # (A similaridade s√≥ funciona bem se o modelo spaCy foi baixado com sucesso!)\n",
    "    try:\n",
    "        similarities = [doc_usuario.similarity(kb_doc) for kb_doc in base_conhecimento['doc']]\n",
    "    except ValueError:\n",
    "        print(\"‚ùå ERRO: A similaridade n√£o pode ser calculada. Verifique se o modelo spaCy foi baixado.\")\n",
    "        return\n",
    "\n",
    "    # Encontra a melhor correspond√™ncia\n",
    "    maior_similaridade = max(similarities)\n",
    "    best_match_index = similarities.index(maior_similaridade)\n",
    "    \n",
    "    print(f\"\\n--- An√°lise da Frase: '{frase_usuario}' ---\")\n",
    "\n",
    "    if maior_similaridade >= limiar_similaridade:\n",
    "        resultado = base_conhecimento.iloc[best_match_index]\n",
    "        print(f\"‚úÖ Correspond√™ncia (Sim. {maior_similaridade:.2f}):\")\n",
    "        print(f\"   - Sintoma: {resultado['Sintoma Cardiovascular']}\")\n",
    "        print(f\"   - Risco: {resultado['Grau de Risco']}\")\n",
    "        print(f\"   - Diagn√≥stico Principal: {resultado['Diagn√≥stico Card√≠aco Principal Associado']}\")\n",
    "        print(f\"   - Correspond√™ncia na base: '{resultado['Express√£o em 1¬™ Pessoa']}'\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è N√£o foi poss√≠vel identificar um sintoma correspondente (Sim. M√°xima: {maior_similaridade:.2f}).\")\n",
    "        print(f\"   Tente reformular a frase usando termos simples.\")\n",
    "    \n",
    "    print(\"------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exemplos de Uso\n",
    "\n",
    "Teste o sistema com diferentes frases. Tente variar a ordem das palavras e sin√¥nimos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- An√°lise da Frase: 'sinto muita dor no peito quando fa√ßo esfor√ßo' ---\n",
      "‚úÖ Correspond√™ncia (Sim. 0.71):\n",
      "   - Sintoma: Angina de Esfor√ßo\n",
      "   - Risco: Alto Risco\n",
      "   - Diagn√≥stico Principal: Doen√ßa Arterial Coronariana (DAC)\n",
      "   - Correspond√™ncia na base: 'Sinto dor ou press√£o no peito ao fazer esfor√ßo f√≠sico.'\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10450/2179773610.py:13: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarities = [doc_usuario.similarity(kb_doc) for kb_doc in base_conhecimento['doc']]\n"
     ]
    }
   ],
   "source": [
    "# Exemplo 1: Dor no peito\n",
    "analisar_sintoma_interativo(\"sinto muita dor no peito quando fa√ßo esfor√ßo\", knowledge_base_df, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- An√°lise da Frase: 'minhas pernas e tornozelos est√£o inchados, com dor no peito' ---\n",
      "‚úÖ Correspond√™ncia (Sim. 0.71):\n",
      "   - Sintoma: Altera√ß√£o na Parede Tor√°cica\n",
      "   - Risco: Baixo Risco\n",
      "   - Diagn√≥stico Principal: Cardiomegalia Cr√¥nica\n",
      "   - Correspond√™ncia na base: 'Observei abaulamentos ou retra√ß√µes no t√≥rax ao respirar.'\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10450/2179773610.py:13: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarities = [doc_usuario.similarity(kb_doc) for kb_doc in base_conhecimento['doc']]\n"
     ]
    }
   ],
   "source": [
    "# Exemplo 2: Edema\n",
    "analisar_sintoma_interativo(\"minhas pernas e tornozelos est√£o inchados, com dor no peito\", knowledge_base_df, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- An√°lise da Frase: 'tenho tontura ao me levantar' ---\n",
      "‚ö†Ô∏è N√£o foi poss√≠vel identificar um sintoma correspondente (Sim. M√°xima: 0.56).\n",
      "   Tente reformular a frase usando termos simples.\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10450/2179773610.py:13: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarities = [doc_usuario.similarity(kb_doc) for kb_doc in base_conhecimento['doc']]\n"
     ]
    }
   ],
   "source": [
    "# Exemplo 3: S√≠ncope / Hipotens√£o\n",
    "analisar_sintoma_interativo(\"tenho tontura ao me levantar\", knowledge_base_df, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- An√°lise da Frase: 'sinto que me falta o ar quando deito' ---\n",
      "‚ö†Ô∏è N√£o foi poss√≠vel identificar um sintoma correspondente (Sim. M√°xima: 0.56).\n",
      "   Tente reformular a frase usando termos simples.\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10450/2179773610.py:13: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarities = [doc_usuario.similarity(kb_doc) for kb_doc in base_conhecimento['doc']]\n"
     ]
    }
   ],
   "source": [
    "# Exemplo 4: Falta de ar deitado\n",
    "analisar_sintoma_interativo(\"sinto que me falta o ar quando deito\", knowledge_base_df, nlp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
